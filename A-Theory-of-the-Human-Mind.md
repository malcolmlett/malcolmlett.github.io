This page describes my overarching theory. Most of the points here are unproven assumptions, based on observations of my own thoughts and influenced from current theories around world. For background on how these conclusions were drawn, see [[Background to A Theory of Mind]].

...work in progress...

Topics:
* All of thought is done by sub-conscious processor modules.
   * Neural pattern matching vs. sequential thought  (vis-a-vis Fast and Slow thinking, Daniel Kahneman)
* Scope of experience of Conscious Thought limited by scope of conscious feedback.
* Consciousness is just a turing machine.
* Free-will - The experience of free-will is an artifact of our tightly integrated mental model, and the labeling of its inputs as 'my thoughts'.

## Minimum Requirements
I believe the most basic form of consciousness needs only the following:
* feedback loop: current state of thought is fed back as an input
* "experience of experiencing" - whatever that is, it's fundamentally important

In practice, it turns out there are some other requirements, without which consciousness doesn't produce anything interesting, and would never have evolved in biological forms:
* sufficiently interesting inputs (senses)
* some form of 'current state' like working memory (this is the 'state' part of a turing machine)
* a minimum level of intelligence
* short to long term memory (required for a useful level of intelligence)

## Theory of "Why" Consciousness Evolved
The high reasoning part of our brain is a Turing machine, but without the reliable stack of a CPU. The architecture of having many processors competing for attention is extremely flexible, but suffers from a susceptibility to circular thought (infinite loops), and stuck thought (dead ends in the state machine).

According to my theory, basic creatures like insects probably employ purely stateless processors. The only state coming from body feedback and hormones. So the evolution of higher reasoning also needed to develop a mechanism for managing the overall processing. That management process is complex, and needs domain knowledge of the data and thought process being carried out. So a natural solution is to just feed the mental state break in as a first class input. Interestingly, this would lead to evolved and learned processors with the processing of problem data and feedback being tightly integrated. 

This doesn't need general intelligence. It's a fundamental architecture. It doesn't need tight integration of problem and feedback data, but it helps. It does need a sufficient level of intelligence applied to that feedback, and if there's no general intelligence, then it basically has to be hard coded. 

So there's basically two options for achieving that level of feedback understanding:
1. Hard coded feedback processing and attention control. Limited data integration. Doesn't require general intelligence. Very unhuman-like. 
2. Fully integrated General intelligence with learning. Human-like. 

In the human case, we are probably born with some basic building blocks of attention control - that do only the most basic of attenuation of repeated signals to avoid tight infinite loops. And then we learn to override those and apply higher reasoning. 

This theory also suggests there is a minimum level of intelligence required for consciousness, because otherwise it cannot control thought well enough. But in contrast, maybe that limit is very small...the slightest bit of self control could rate on the consciousness scale. 

### Follow ups
We know which parts of the brain are associated with high level thinking. It would be interesting to research what animals have the same components. More on this later...

Control Theory may help to fill in the gaps. In particular, it may help define the lower limit of intelligence required for consciousness and thus for high-order reasoning via turing machine architecture.
 

## See Also
* [[What is Consciousness]]