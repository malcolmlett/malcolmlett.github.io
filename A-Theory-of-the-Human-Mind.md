This page describes my overarching theory. Most of the points here are unproven assumptions, based on observations of my own thoughts and influenced from current theories around world.

...work in progress...

Topics:
* All of thought is done by sub-conscious processor modules.
   * Neural pattern matching vs. sequential thought  (vis-a-vis Fast and Slow thinking, Daniel Kahneman)
* Scope of experience of Conscious Thought limited by scope of conscious feedback.
* Consciousness is just a turing machine.
* Free-will - The experience of free-will is an artifact of our tightly integrated mental model, and the labeling of its inputs as 'my thoughts'.

## Minimum Requirements
I believe the most basic form of consciousness needs only the following:
* feedback loop: current state of thought is fed back as an input
* "experience of experiencing" - whatever that is, it's fundamentally important

In practice, it turns out there are some other requirements, without which consciousness doesn't produce anything interesting, and would never have evolved in biological forms:
* sufficiently interesting inputs (senses)
* some form of 'current state' like working memory (this is the 'state' part of a turing machine)
* a minimum level of intelligence
* short to long term memory (required for a useful level of intelligence)

## Theory of "Why" Consciousness Evolved
The high reasoning part of our brain is a Turing machine, but without the reliable stack of a CPU. The architecture of having many processors competing for attention is extremely flexible, but suffers from a susceptibility to circular thought (infinite loops), and stuck thought (dead ends in the state machine).

According to my theory, basic creatures like insects probably employ purely stateless processors. The only state coming from body feedback and hormones. So the evolution of higher reasoning also needed to develop a mechanism for managing the overall processing. That management process is complex, and needs domain knowledge of the data and thought process being carried out. So a natural solution is to just feed the mental state break in as a first class input. Interestingly, this would lead to evolved and learned processors with the processing of problem data and feedback being tightly integrated. 

This doesn't need general intelligence. It's a fundamental architecture. It doesn't need tight integration of problem and feedback data, but it helps. It does need a sufficient level of intelligence applied to that feedback, and if there's no general intelligence, then it basically has to be hard coded. 

So there's basically two options for achieving that level of feedback understanding:
1. Hard coded feedback processing and attention control. Limited data integration. Doesn't require general intelligence. Very unhuman-like. 
2. Fully integrated General intelligence with learning. Human-like. 

In the human case, we are probably born with some basic building blocks of attention control - that do only the most basic of attenuation of repeated signals to avoid tight infinite loops. And then we learn to override those and apply higher reasoning. 

This theory also suggests there is a minimum level of intelligence required for consciousness, because otherwise it cannot control thought well enough. But in contrast, maybe that limit is very small...the slightest bit of self control could rate on the consciousness scale. 

### Follow ups
We know which parts of the brain are associated with high level thinking. It would be interesting to research what animals have the same components. More on this later...

Control Theory may help to fill in the gaps. In particular, it may help define the lower limit of intelligence required for consciousness and thus for high-order reasoning via turing machine architecture.

## Why is individual intelligence limited?
The architecture I have theorised does not imply any limits. I believe the same architecture is used throughout all mammals at the least, to varying scales. But clearly the DNA of a species puts limits on the capacity of an individual to increase their intelligence. But why? Why is it that a dog cannot learn to be as intelligent as a human? 

An answer to this may lie in the fundamental difference between what is controlled by DNA and what is learned. 

DNA must set some controls on regions of the brain. The visual system presumably cannot be re-purposed to rationalise about thermal systems. And that makes sense - the visual processing system is architected with a focus on visual inputs...so it's learning is focused on that. 

Additionally, learning requires a fitness measure, which will likely be heavily controlled by DNA with little, if any, adjustments possible from life experiences. The fitness measure of each region is brain will be heavily focused on a particular task. This likely explains why the brain seems so conveniently modular - learning is more efficient when focused on one thing.

So the limits of an individual's intelligence growth are imposed by the specific focused tasks that evolution has selected for.

A concrete example may actually lie in the way that we _can_ increase intelligence to an extent. Individual regions of brain can increase in size. For example London cabbies, with their enlarged memory centre. But it is likely that our biology imposes limits on that growth. Any fitness function will incorporate efficiency, and there is an inherent trade-off between size and efficiency. The limit is "soft", and can be stretched, but only so far. 

Beyond that, each brain region had an inherent capacity. This is like a (roughly) fixed number of neurons that can learn anything its given, but only to the resolution possible within that number of neurons. 

## See Also
* [[What is Consciousness]]